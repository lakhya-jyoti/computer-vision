{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Image folder link: https://www.kaggle.com/datasets/sourcerer/flowers-recognition-4267-train-50-test-split"
      ],
      "metadata": {
        "id": "2casmxAnBgM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfabNiXmp3QB",
        "outputId": "5517e10d-6c85-45d3-bc80-3aa42aa138a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEL2CPywaFjW",
        "outputId": "7a910e24-fce0-4431-d3fd-b93e4feff90e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aZQcQvjBJ6Kw"
      },
      "outputs": [],
      "source": [
        "images_path = \"/content/drive/My Drive/Colab Notebooks/flowers.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(images_path, 'r') as zip:\n",
        "  zip.extractall()"
      ],
      "metadata": {
        "id": "FCZm22Ar-HkJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYdoct8t-WmI",
        "outputId": "b1401835-c602-4317-ed57-a4c4570a6cca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  flowers\t__MACOSX  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Keras Modules**"
      ],
      "metadata": {
        "id": "9zAu7XNsKSUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "hUei-IQc-fcP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the CNN Classifier**"
      ],
      "metadata": {
        "id": "fnjymNIEKXOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising the CNN classifier\n",
        "classifier = Sequential()\n",
        "\n",
        "# Add a Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Add a Max Pooling layer of size 2X2\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Add another Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Adding another pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Add another Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Adding another pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Flattening the layer before fully connected layers\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Adding a fully connected layer with 512 neurons\n",
        "classifier.add(Dense(units = 512, activation = 'relu'))\n",
        "\n",
        "# Adding dropout with probability 0.5\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# Adding a fully connected layer with 128 neurons\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "\n",
        "# The final output layer with 5 neuron to predict the categorical classifcation\n",
        "classifier.add(Dense(units = 5, activation = 'softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iXfbbSPKasu",
        "outputId": "53121f0e-8a0d-4438-e975-2977bd80a54e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compiling the CNN classifier with Adam optimizer (default Learning rate and other parameters) and Categorical Crossentropy as loss function and Accuracy as the metric to monitor**\n",
        "\n",
        "Adam Configuration Parameters\n",
        "1. alpha. Also referred to as the learning rate or step size. The proportion that weights are updated (e.g. 0.001). Larger values (e.g. 0.3) results in faster initial learning before the rate is updated. Smaller values (e.g. 1.0-5) slow learning right down during training\n",
        "2. beta1. The exponential decay rate for the first moment estimates (e.g. 0.9).\n",
        "3. beta2. The exponential decay rate for the second-moment estimates (e.g. 0.999). This value should be set close to 1.0 on problems with a sparse gradient (e.g. NLP and computer vision problems).\n",
        "4. epsilon. Is a very small number to prevent any division by zero in the implementation (e.g. 10E-8)."
      ],
      "metadata": {
        "id": "6M0-RhrFMLcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
        "classifier.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqDYOfy1MWCy",
        "outputId": "85b9c5bc-9702-469d-f6b5-e560a5410246"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Pre-processing**\n",
        "ImageDataGenerator is a powerful preprocessing utility to generate training and testing data with common data augmentation techniques. It can also be used to generate training data from Images stored in hierarchical directory structures. For more options of ImageDataGenerator go to https://keras.io/preprocessing/image/"
      ],
      "metadata": {
        "id": "Pnz5TveVNkNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Create data generator for training data with data augmentation and normalizing all\n",
        "# values by 255\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Setting training data generator's source directory\n",
        "# Setting the target size to resize all the images to (64,64) as the model input layer expects 32X32 images\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('./flowers/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "# Setting testing data generator's source directory\n",
        "test_set = test_datagen.flow_from_directory('./flowers/test',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "\n",
        "# There are 3823 training images and 500 test images in total\n",
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch = int(3823/32),\n",
        "                         epochs = 20,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = int(500/32))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "BkkhK1iANooq",
        "outputId": "c2a7405c-8620-4e5e-cff6-41be36c2b644"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4267 images belonging to 5 classes.\n",
            "Found 50 images belonging to 5 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'fit_generator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b7161a143313>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# There are 3823 training images and 500 test images in total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m classifier.fit_generator(training_set,\n\u001b[0m\u001b[1;32m     31\u001b[0m                          \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3823\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                          \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'fit_generator'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**save the model and its weights after training**"
      ],
      "metadata": {
        "id": "BRSB3Stl_qHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('./classifier.h5')\n",
        "\n",
        "classifier.save_weights('./classifier_weights.weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd7_kDdF_r8D",
        "outputId": "b60fef4a-3ede-4b18-bf82-284bd4e37f6e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2PaMqqd_6Wt",
        "outputId": "05675aac-418a-475d-d32c-b9087705d2f8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.h5  classifier_weights.weights.h5  drive  flowers  __MACOSX\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTING THE MODEL**"
      ],
      "metadata": {
        "id": "hRuzdvbz_-wP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the pretrained model**"
      ],
      "metadata": {
        "id": "KaPxDwu4AF0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the pre trained model from the HDF5 file saved previously\n",
        "pretrained_model = load_model('./classifier.h5')\n",
        "pretrained_model.load_weights('./classifier_weights.weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn7KBGZXACVI",
        "outputId": "fd577ca6-d7cd-40da-a1f4-3f7c18a6487a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing the model on a test image from one of the test folders**"
      ],
      "metadata": {
        "id": "kv2rtnjJAObn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Get the absolute path to the image\n",
        "image_path = os.path.abspath('./flowers/test/daisy/5547758_eea9edfd54_n.jpg')\n",
        "\n",
        "test_image = cv2.imread(image_path)\n",
        "\n",
        "# Check if the image was loaded correctly\n",
        "if test_image is None:\n",
        "    print(\"Error: Image could not be loaded. Check the file path.\")\n",
        "else:\n",
        "    # ... rest of the code\n",
        "    # Resize the image to 64X64 shape to be compatible with the model\n",
        "    test_image = cv2.resize(test_image,(64,64))\n",
        "\n",
        "    # Check if the size of the Image array is compatible with Keras model\n",
        "    print(test_image.shape)\n",
        "\n",
        "    # If not compatible expand the dimensions to match with the Keras Input\n",
        "    test_image = np.expand_dims(test_image, axis = 0)\n",
        "    test_image =test_image*1/255.0\n",
        "\n",
        "    #Check the size of the Image array again\n",
        "    print('After expand_dims: '+ str(test_image.shape))\n",
        "\n",
        "    #Predict the result of the test image\n",
        "    # 'classifier' was used instead of 'pretrained_model'\n",
        "    result = pretrained_model.predict(test_image)\n",
        "\n",
        "    # Check the indices Image Data Generator has allotted to each folder\n",
        "    classes_dict = training_set.class_indices\n",
        "    print(classes_dict)\n",
        "\n",
        "    # Creating a list of classes in test set for showing the result as the folder name\n",
        "    prediction_class = []\n",
        "    for class_name,index in classes_dict.items():\n",
        "      prediction_class.append(class_name)\n",
        "\n",
        "    print(result[0])\n",
        "\n",
        "    # Index of the class with maximum probability\n",
        "    predicted_index = np.argmax(result[0])\n",
        "\n",
        "    # Print the name of the class\n",
        "    print(prediction_class[predicted_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE_hxY2zAPXG",
        "outputId": "8071a75e-b012-416f-bb75-856e57886840"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 64, 3)\n",
            "After expand_dims: (1, 64, 64, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
            "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n",
            "[0.20088059 0.19989228 0.23013908 0.19726212 0.17182587]\n",
            "rose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating a report on the test data**"
      ],
      "metadata": {
        "id": "fdlCg3rSAUf4"
      }
    },
    {
      "source": [
        "# Re-initalizing the test data generator with shuffle=False to create the confusion matrix\n",
        "test_set = test_datagen.flow_from_directory('./flowers/test',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            shuffle=False,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "# Predict the whole generator to get predictions\n",
        "Y_pred = classifier.predict(test_set, steps=int(500/32+1))\n",
        "\n",
        "# Find out the predictions classes with maximum probability\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# Utilities for confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Printing the confusion matrix based on the actual data vs predicted data.\n",
        "print(confusion_matrix(test_set.classes, y_pred))\n",
        "\n",
        "# Printing the classification report\n",
        "print(classification_report(test_set.classes, y_pred, target_names=prediction_class))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFr-XH-PBRsS",
        "outputId": "3f938a8d-0342-4af2-ce79-3296c256fa5d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50 images belonging to 5 classes.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "[[ 0  1  9  0  0]\n",
            " [ 1  0  9  0  0]\n",
            " [ 0  2  8  0  0]\n",
            " [ 1  0  9  0  0]\n",
            " [ 0  0 10  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       daisy       0.00      0.00      0.00        10\n",
            "   dandelion       0.00      0.00      0.00        10\n",
            "        rose       0.18      0.80      0.29        10\n",
            "   sunflower       0.00      0.00      0.00        10\n",
            "       tulip       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.16        50\n",
            "   macro avg       0.04      0.16      0.06        50\n",
            "weighted avg       0.04      0.16      0.06        50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}